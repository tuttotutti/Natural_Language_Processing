{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Word2Vec_SkipGram**\n",
        "\n",
        "1.   Sources:\n",
        "\n",
        "\n",
        "*   Training_text.txt\n",
        "*   stopwords.txt\n",
        "\n",
        "\n",
        "2.   Flow:\n",
        "* Remove all the stopwords and the punctuation marks\n",
        "* Choose embedding_size (the num of dimensions) = 5 (because of too many topics, 2 axes are not enough to express the closeness of the words)\n",
        "* Generate random matrices of values for vectors for each word in center_words and context_words => make the length of each vector = 1 (to avoid dot_prod of any word is too big for similar words)\n",
        "* No update thru 25 epochs:\n",
        "   + Set the window_size (the num of neighbors on each side) = 3, the num of random unrelated words in the text = 3 (to label 0 to train together with 1)\n",
        "   + Loop to collect each center word and its neighbors and the random unrelated words\n",
        "   + Cal the score, errors (using sigmoid: 1 is very similar, 0 is very different)\n",
        "   + Update by dif.errors.learning_rate (make what’s supposed to be closer closer, what’s supposed to be farer farer)\n",
        "   + *Note: afte update here, the length changes\n",
        "   + Normalize the vector length\n",
        "\n"
      ],
      "metadata": {
        "id": "_ZkQBcIBzGn0"
      }
    }
  ]
}